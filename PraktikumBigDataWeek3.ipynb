{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOeiwhmqHx6Q6d1JEudG38M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1. Pengenalan Spark DataFrames\n","Spark DataFrame menyediakan struktur data yang optimal dengan operasi yang dioptimalkan untuk pemrosesan data besar, yang sangat mirip dengan DataFrame di Pandas atau di RDBMS.\n"],"metadata":{"id":"_6_U3Rl_VoJ1"}},{"cell_type":"markdown","source":["**Tugas 1:** Buat DataFrame sederhana di Spark dan eksplorasi beberapa fungsi dasar yang tersedia"],"metadata":{"id":"gRqf6LcBVz-P"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ScfUIGInVmKL","executionInfo":{"status":"ok","timestamp":1757385695035,"user_tz":-420,"elapsed":22220,"user":{"displayName":"Ilyasa Abiyyu","userId":"07140171144983850462"}},"outputId":"c780d7c2-7854-4e33-e658-c9bdaed415bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------+------+\n","|EmployeeName|Department|Salary|\n","+------------+----------+------+\n","|       James|     Sales|  3000|\n","|     Michael|     Sales|  4600|\n","|      Robert|     Sales|  4100|\n","|       Maria|   Finance|  3000|\n","+------------+----------+------+\n","\n"]}],"source":["# Contoh membuat DataFrame sederhana dan operasi dasar\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName('HandsOnPertemuan3').getOrCreate()\n","\n","data = [('James', 'Sales', 3000),\n","        ('Michael', 'Sales', 4600),\n","        ('Robert', 'Sales', 4100),\n","        ('Maria', 'Finance', 3000)]\n","columns = ['EmployeeName', 'Department', 'Salary']\n","\n","df = spark.createDataFrame(data, schema=columns)\n","df.show()"]},{"cell_type":"markdown","source":["# 2. Transformasi Dasar dengan DataFrames\n","Pemrosesan data meliputi transformasi seperti filtering, selections, dan aggregations. Spark menyediakan cara efisien untuk melaksanakan operasi ini."],"metadata":{"id":"qreQEacUWFDs"}},{"cell_type":"markdown","source":["**Tugas 2:** Gunakan operasi filter, select, groupBy untuk mengekstrak informasi dari data, serta lakukan agregasi data untuk mendapatkan insight tentang dataset menggunakan perintah seperti mean, max, sum."],"metadata":{"id":"wCUlj9ptWKvc"}},{"cell_type":"code","source":["# Contoh operasi transformasi DataFrame\n","select('EmployeeName', 'Salary').show()\n","filter(df['Salary'] > 3000).show()\n","groupBy('Department').avg('Salary').show()"],"metadata":{"id":"wNLKTd6tZn7e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Implementasi dari contoh operasi transformasi DataFrame diatas"],"metadata":{"id":"hJxo0YliZoia"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","# Membuat SparkSession\n","spark = SparkSession.builder.appName(\"DataFrameExample\").getOrCreate()\n","\n","# Contoh DataFrame\n","data = [(\"Alice\", \"Engineering\", 70000),\n","        (\"Bob\", \"Sales\", 60000),\n","        (\"Charlie\", \"Engineering\", 85000),\n","        (\"David\", \"Sales\", 65000),\n","        (\"Eve\", \"Marketing\", 55000)]\n","columns = [\"EmployeeName\", \"Department\", \"Salary\"]\n","df = spark.createDataFrame(data, columns)\n","\n","# Operasi Transformasi DataFrame\n","\n","# Memilih Kolom select\n","df.select('EmployeeName', 'Salary').show()\n","df.filter(df['Salary'] > 64000).show()\n","df.groupBy('Department').avg('Salary').show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcHztB4lZo_I","executionInfo":{"status":"ok","timestamp":1757496309354,"user_tz":-420,"elapsed":2213,"user":{"displayName":"Ilyasa Abiyyu","userId":"07140171144983850462"}},"outputId":"5d795007-e9c5-490e-9482-7001827c6dde"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+------+\n","|EmployeeName|Salary|\n","+------------+------+\n","|       Alice| 70000|\n","|         Bob| 60000|\n","|     Charlie| 85000|\n","|       David| 65000|\n","|         Eve| 55000|\n","+------------+------+\n","\n","+------------+-----------+------+\n","|EmployeeName| Department|Salary|\n","+------------+-----------+------+\n","|       Alice|Engineering| 70000|\n","|     Charlie|Engineering| 85000|\n","|       David|      Sales| 65000|\n","+------------+-----------+------+\n","\n","+-----------+-----------+\n","| Department|avg(Salary)|\n","+-----------+-----------+\n","|      Sales|    62500.0|\n","|Engineering|    77500.0|\n","|  Marketing|    55000.0|\n","+-----------+-----------+\n","\n"]}]},{"cell_type":"markdown","source":["# 3. Bekerja dengan Tipe Data Kompleks\n","Spark mendukung tipe data yang kompleks seperti maps, arrays, dan structs yang memungkinkan operasi yang lebih kompleks pada dataset yang kompleks.\n","\n"],"metadata":{"id":"8NXMafurbjxs"}},{"cell_type":"markdown","source":["**Tugas 3:** Eksplorasi bagaimana mengolah tipe data kompleks dalam Spark DataFrames."],"metadata":{"id":"uJC87jx_bnrv"}},{"cell_type":"code","source":["# Contoh manipulasi tipe data kompleks\n","df.withColumn('SalaryBonus', df['Salary'] * 0.1).show()\n","df.withColumn('TotalCompensation', df['Salary'] + df['SalaryBonus']).show()"],"metadata":{"id":"MN49xcE1-9EL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Implementasi dari contoh operasi transformasi DataFrame diatas"],"metadata":{"id":"QksQ4MMA-77U"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","# Inisialisasi SparkSession\n","spark = SparkSession.builder.appName('ComplexDataManipulation').getOrCreate()\n","\n","# Membuat contoh DataFrame\n","data = [('James', 'Sales', 3000),\n","        ('Michael', 'Sales', 4600),\n","        ('Robert', 'Sales', 4100)]\n","columns = ['EmployeeName', 'Department', 'Salary']\n","df = spark.createDataFrame(data, columns)\n","\n","# Tambah kolom 'SalaryBonus' dan 'TotalCompensation'\n","df_with_bonus = df.withColumn('SalaryBonus', col('Salary') * 0.1)\n","\n","df_final = df_with_bonus.withColumn('TotalCompensation', col('Salary') + col('SalaryBonus'))\n","\n","# Tampilkan DataFrame hasil akhir\n","df_final.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QGCYCY8vbodL","executionInfo":{"status":"ok","timestamp":1757497743441,"user_tz":-420,"elapsed":856,"user":{"displayName":"Ilyasa Abiyyu","userId":"07140171144983850462"}},"outputId":"4b34443d-7d15-4df6-866d-e824d3f1009a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------+------+-----------+-----------------+\n","|EmployeeName|Department|Salary|SalaryBonus|TotalCompensation|\n","+------------+----------+------+-----------+-----------------+\n","|       James|     Sales|  3000|      300.0|           3300.0|\n","|     Michael|     Sales|  4600|      460.0|           5060.0|\n","|      Robert|     Sales|  4100|      410.0|           4510.0|\n","+------------+----------+------+-----------+-----------------+\n","\n"]}]},{"cell_type":"markdown","source":["# 4. Operasi Data Lanjutan\n","Menggunakan Spark untuk operasi lanjutan seperti window functions, user-defined functions (UDFs), dan mengoptimalkan query."],"metadata":{"id":"QRBR8D3XdImP"}},{"cell_type":"markdown","source":["**Tugas 4:** Implementasikan window function untuk menghitung running totals atau rangkings.\n"],"metadata":{"id":"yt3UZ_U3dJTD"}},{"cell_type":"code","source":["# Contoh menggunakan window functions\n","from pyspark.sql.window import Window\n","from pyspark.sql import functions as F\n","\n","windowSpec = Window.partitionBy('Department').orderBy('Salary')\n","df.withColumn('Rank', F.rank().over(windowSpec)).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQFMHTZidJmw","executionInfo":{"status":"ok","timestamp":1757387510412,"user_tz":-420,"elapsed":2691,"user":{"displayName":"Ilyasa Abiyyu","userId":"07140171144983850462"}},"outputId":"2321a002-f42d-4790-869c-257e085e6aaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------+------+----+\n","|EmployeeName|Department|Salary|Rank|\n","+------------+----------+------+----+\n","|       James|     Sales|  3000|   1|\n","|      Robert|     Sales|  4100|   2|\n","|     Michael|     Sales|  4600|   3|\n","+------------+----------+------+----+\n","\n"]}]},{"cell_type":"markdown","source":["# 5. Kesimpulan dan Eksplorasi Lebih Lanjut\n","Review apa yang telah dipelajari tentang pemrosesan data menggunakan Spark dan eksplorasi teknik lebih lanjut untuk mengoptimalkan pemrosesan data Anda.\n","Tugas 5:"],"metadata":{"id":"23AwbVZKgEMq"}},{"cell_type":"markdown","source":["**Tugas 5:**\n","\n","- Unduh dataset besar dari Kaggle atau sumber lainnya.\n","- Input data csv yang telah di download, kemudian load dan simpan data ke dalam pyspark.\n","- Setelah data berhasil di load menggunakan pyspark, lakukan manipulasi data untuk memperoleh informasi yang dibutuhkan"],"metadata":{"id":"C-Ae9_ibgEhZ"}},{"cell_type":"code","source":["import os\n","from pyspark.sql import SparkSession\n","\n","# Inisialisasi Sesi Spark\n","spark = SparkSession.builder.appName(\"ColabDataLoading\").getOrCreate()\n","\n","# Jika Anda mengunggahnya secara langsung dicollab, jalurnya hanya nama file\n","file_path = \"top_50_2023.csv\"\n","\n","# Memuat Data\n","try:\n","    df = spark.read.csv(file_path, header=True, inferSchema=True)\n","\n","    print(\"Data berhasil dimuat dari sistem berkas Colab:\")\n","    df.show(5)\n","\n","    print(\"DataFrame Schema:\")\n","    df.printSchema()\n","\n","except Exception as e:\n","    print(f\"Terjadi kesalahan saat memuat data: {e}\")\n","\n","# Stop Spark Session\n","spark.stop()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3mOPJGPvgE6l","executionInfo":{"status":"ok","timestamp":1757389097169,"user_tz":-420,"elapsed":1737,"user":{"displayName":"Ilyasa Abiyyu","userId":"07140171144983850462"}},"outputId":"e04a12f9-0b0e-4538-9d97-2a398346c7df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data berhasil dimuat dari sistem berkas Colab:\n","+--------------+--------------------+-----------+------------------+--------------------+------------+-------+------+--------+------------+----------------+--------+-----------+---+-------+----+-----------+--------------+----------+\n","|   artist_name|          track_name|is_explicit|album_release_date|              genres|danceability|valence|energy|loudness|acousticness|instrumentalness|liveness|speechiness|key|  tempo|mode|duration_ms|time_signature|popularity|\n","+--------------+--------------------+-----------+------------------+--------------------+------------+-------+------+--------+------------+----------------+--------+-----------+---+-------+----+-----------+--------------+----------+\n","|   Miley Cyrus|             Flowers|      false|        2023-08-18|             ['pop']|       0.706|  0.632| 0.691|  -4.775|      0.0584|         6.99E-5|  0.0232|     0.0633|  0|118.048|   1|     200600|             4|        94|\n","|           SZA|           Kill Bill|      false|        2022-12-08|['pop', 'r&b', 'r...|       0.644|  0.418| 0.735|  -5.747|      0.0521|           0.144|   0.161|     0.0391|  8|  88.98|   1|     153947|             4|        86|\n","|  Harry Styles|           As It Was|      false|        2022-05-20|             ['pop']|        0.52|  0.662| 0.731|  -5.338|       0.342|         0.00101|   0.311|     0.0557|  6| 173.93|   0|     167303|             4|        95|\n","|     Jung Kook|Seven (feat. Latt...|       true|        2023-11-03|           ['k-pop']|        0.79|  0.872| 0.831|  -4.185|       0.312|             0.0|  0.0797|      0.044| 11|124.987|   1|     183551|             4|        90|\n","|Eslabon Armado|     Ella Baila Sola|      false|        2023-04-28|['corrido', 'corr...|       0.668|  0.834| 0.758|  -5.176|       0.483|         1.89E-5|  0.0837|     0.0332|  5|147.989|   0|     165671|             3|        86|\n","+--------------+--------------------+-----------+------------------+--------------------+------------+-------+------+--------+------------+----------------+--------+-----------+---+-------+----+-----------+--------------+----------+\n","only showing top 5 rows\n","\n","DataFrame Schema:\n","root\n"," |-- artist_name: string (nullable = true)\n"," |-- track_name: string (nullable = true)\n"," |-- is_explicit: boolean (nullable = true)\n"," |-- album_release_date: date (nullable = true)\n"," |-- genres: string (nullable = true)\n"," |-- danceability: double (nullable = true)\n"," |-- valence: double (nullable = true)\n"," |-- energy: double (nullable = true)\n"," |-- loudness: double (nullable = true)\n"," |-- acousticness: double (nullable = true)\n"," |-- instrumentalness: double (nullable = true)\n"," |-- liveness: double (nullable = true)\n"," |-- speechiness: double (nullable = true)\n"," |-- key: integer (nullable = true)\n"," |-- tempo: double (nullable = true)\n"," |-- mode: integer (nullable = true)\n"," |-- duration_ms: integer (nullable = true)\n"," |-- time_signature: integer (nullable = true)\n"," |-- popularity: integer (nullable = true)\n","\n"]}]}]}